{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CIFAR-10 Hyperparameter Tuning with Ray Tune\n",
                "\n",
                "This notebook demonstrates how to use Ray Tune for hyperparameter optimization with your existing code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "import common\n",
                "import ray"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load CIFAR-10 Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-16 21:20:50,181\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n"
                    ]
                }
            ],
            "source": [
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "\n",
                "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
                "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
                "\n",
                "# Initialize Ray and put datasets in object store to avoid large actor serialization\n",
                "ray.init(ignore_reinit_error=True)\n",
                "trainset_ref = ray.put(trainset)\n",
                "testset_ref = ray.put(testset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define the Model (same as cifar_regular.ipynb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Net(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
                "        self.fc1 = nn.Linear(64 * 5 * 5, 120)\n",
                "        self.fc2 = nn.Linear(120, 84)\n",
                "        self.fc3 = nn.Linear(84, 10)\n",
                "        self.fc4 = nn.Linear(64 * 5 * 5, 10)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.conv1(x)))\n",
                "        x = self.pool(F.relu(self.conv2(x)))\n",
                "        x = torch.flatten(x, 1)\n",
                "        x = self.fc4(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Hyperparameter Search\n",
                "\n",
                "This will try different combinations of:\n",
                "- Learning rates (1e-4 to 1e-1)\n",
                "- Batch sizes (32, 64, 128, 256)\n",
                "- Optimizers (SGD, Adam)\n",
                "- Momentum values (0.8 to 0.99)\n",
                "- Weight decay (1e-5 to 1e-2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div class=\"tuneStatus\">\n",
                            "  <div style=\"display: flex;flex-direction: row\">\n",
                            "    <div style=\"display: flex;flex-direction: column;\">\n",
                            "      <h3>Tune Status</h3>\n",
                            "      <table>\n",
                            "<tbody>\n",
                            "<tr><td>Current time:</td><td>2025-12-16 21:51:50</td></tr>\n",
                            "<tr><td>Running for: </td><td>00:30:51.57        </td></tr>\n",
                            "<tr><td>Memory:      </td><td>11.3/16.0 GiB      </td></tr>\n",
                            "</tbody>\n",
                            "</table>\n",
                            "    </div>\n",
                            "    <div class=\"vDivider\"></div>\n",
                            "    <div class=\"systemInfo\">\n",
                            "      <h3>System Info</h3>\n",
                            "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 0/10 CPUs, 0/0 GPUs\n",
                            "    </div>\n",
                            "    \n",
                            "  </div>\n",
                            "  <div class=\"hDivider\"></div>\n",
                            "  <div class=\"trialStatus\">\n",
                            "    <h3>Trial Status</h3>\n",
                            "    <table>\n",
                            "<thead>\n",
                            "<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th>optimizer  </th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
                            "</thead>\n",
                            "<tbody>\n",
                            "<tr><td>train_tune_06a59_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.0112082  </td><td style=\"text-align: right;\">  0.901514</td><td>sgd        </td><td style=\"text-align: right;\">   5.01552e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000141254</td><td style=\"text-align: right;\">  0.819222</td><td>sgd        </td><td style=\"text-align: right;\">   0.00383685 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.0577233  </td><td style=\"text-align: right;\">  0.850219</td><td>sgd        </td><td style=\"text-align: right;\">   1.18507e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.0205148  </td><td style=\"text-align: right;\">  0.887425</td><td>adam       </td><td style=\"text-align: right;\">   0.00610642 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.00089599 </td><td style=\"text-align: right;\">  0.954429</td><td>sgd        </td><td style=\"text-align: right;\">   0.000742339</td></tr>\n",
                            "<tr><td>train_tune_06a59_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000565417</td><td style=\"text-align: right;\">  0.979436</td><td>sgd        </td><td style=\"text-align: right;\">   0.000605215</td></tr>\n",
                            "<tr><td>train_tune_06a59_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.000619493</td><td style=\"text-align: right;\">  0.916088</td><td>sgd        </td><td style=\"text-align: right;\">   0.00331863 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00156748 </td><td style=\"text-align: right;\">  0.866355</td><td>sgd        </td><td style=\"text-align: right;\">   3.36094e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.000339513</td><td style=\"text-align: right;\">  0.821342</td><td>adam       </td><td style=\"text-align: right;\">   0.00232802 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.0548016  </td><td style=\"text-align: right;\">  0.88233 </td><td>adam       </td><td style=\"text-align: right;\">   0.00522649 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000478927</td><td style=\"text-align: right;\">  0.877598</td><td>adam       </td><td style=\"text-align: right;\">   1.55358e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.0285169  </td><td style=\"text-align: right;\">  0.905198</td><td>adam       </td><td style=\"text-align: right;\">   0.00181653 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0197379  </td><td style=\"text-align: right;\">  0.945516</td><td>adam       </td><td style=\"text-align: right;\">   2.78181e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.0890713  </td><td style=\"text-align: right;\">  0.813886</td><td>sgd        </td><td style=\"text-align: right;\">   2.19421e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00038152 </td><td style=\"text-align: right;\">  0.915021</td><td>sgd        </td><td style=\"text-align: right;\">   0.00758267 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.00048092 </td><td style=\"text-align: right;\">  0.974332</td><td>sgd        </td><td style=\"text-align: right;\">   1.13927e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000301253</td><td style=\"text-align: right;\">  0.880994</td><td>sgd        </td><td style=\"text-align: right;\">   0.00595714 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00248259 </td><td style=\"text-align: right;\">  0.989389</td><td>sgd        </td><td style=\"text-align: right;\">   0.00884364 </td></tr>\n",
                            "<tr><td>train_tune_06a59_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0866373  </td><td style=\"text-align: right;\">  0.833787</td><td>sgd        </td><td style=\"text-align: right;\">   3.10005e-05</td></tr>\n",
                            "<tr><td>train_tune_06a59_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.000238271</td><td style=\"text-align: right;\">  0.906623</td><td>sgd        </td><td style=\"text-align: right;\">   1.70152e-05</td></tr>\n",
                            "</tbody>\n",
                            "</table>\n",
                            "  </div>\n",
                            "</div>\n",
                            "<style>\n",
                            ".tuneStatus {\n",
                            "  color: var(--jp-ui-font-color1);\n",
                            "}\n",
                            ".tuneStatus .systemInfo {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            ".tuneStatus td {\n",
                            "  white-space: nowrap;\n",
                            "}\n",
                            ".tuneStatus .trialStatus {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            ".tuneStatus h3 {\n",
                            "  font-weight: bold;\n",
                            "}\n",
                            ".tuneStatus .hDivider {\n",
                            "  border-bottom-width: var(--jp-border-width);\n",
                            "  border-bottom-color: var(--jp-border-color0);\n",
                            "  border-bottom-style: solid;\n",
                            "}\n",
                            ".tuneStatus .vDivider {\n",
                            "  border-left-width: var(--jp-border-width);\n",
                            "  border-left-color: var(--jp-border-color0);\n",
                            "  border-left-style: solid;\n",
                            "  margin: 0.5em 1em 0.5em 1em;\n",
                            "}\n",
                            "</style>\n"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-16 21:51:50,769\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
                        "2025-12-16 21:51:50,774\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59' in 0.0039s.\n",
                        "2025-12-16 21:51:50,790\tINFO tune.py:1041 -- Total run time: 1851.60 seconds (1851.56 seconds for the tuning loop).\n",
                        "2025-12-16 21:51:50,790\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
                        "Resume experiment with: Tuner.restore(path=\"/Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59\", trainable=...)\n",
                        "2025-12-16 21:51:50,800\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 20 trial(s):\n",
                        "- train_tune_06a59_00000: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00000: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00000_0_batch_size=64,lr=0.0112,momentum=0.9015,optimizer=sgd,weight_decay=0.0001_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00001: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00001: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00001_1_batch_size=32,lr=0.0001,momentum=0.8192,optimizer=sgd,weight_decay=0.0038_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00002: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00002: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00002_2_batch_size=128,lr=0.0577,momentum=0.8502,optimizer=sgd,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00003: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00003: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00003_3_batch_size=64,lr=0.0205,momentum=0.8874,optimizer=adam,weight_decay=0.0061_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00004: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00004: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00004_4_batch_size=256,lr=0.0009,momentum=0.9544,optimizer=sgd,weight_decay=0.0007_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00005: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00005: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00005_5_batch_size=32,lr=0.0006,momentum=0.9794,optimizer=sgd,weight_decay=0.0006_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00006: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00006: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00006_6_batch_size=128,lr=0.0006,momentum=0.9161,optimizer=sgd,weight_decay=0.0033_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00007: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00007: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00007_7_batch_size=128,lr=0.0016,momentum=0.8664,optimizer=sgd,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00008: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00008: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00008_8_batch_size=128,lr=0.0003,momentum=0.8213,optimizer=adam,weight_decay=0.0023_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00009: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00009: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00009_9_batch_size=32,lr=0.0548,momentum=0.8823,optimizer=adam,weight_decay=0.0052_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00010: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00010: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00010_10_batch_size=32,lr=0.0005,momentum=0.8776,optimizer=adam,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00011: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00011: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00011_11_batch_size=128,lr=0.0285,momentum=0.9052,optimizer=adam,weight_decay=0.0018_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00012: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00012: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00012_12_batch_size=256,lr=0.0197,momentum=0.9455,optimizer=adam,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00013: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00013: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00013_13_batch_size=32,lr=0.0891,momentum=0.8139,optimizer=sgd,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00014: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00014: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00014_14_batch_size=128,lr=0.0004,momentum=0.9150,optimizer=sgd,weight_decay=0.0076_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00015: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00015: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00015_15_batch_size=256,lr=0.0005,momentum=0.9743,optimizer=sgd,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00016: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00016: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00016_16_batch_size=256,lr=0.0003,momentum=0.8810,optimizer=sgd,weight_decay=0.0060_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00017: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00017: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00017_17_batch_size=128,lr=0.0025,momentum=0.9894,optimizer=sgd,weight_decay=0.0088_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00018: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00018: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00018_18_batch_size=256,lr=0.0866,momentum=0.8338,optimizer=sgd,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "- train_tune_06a59_00019: FileNotFoundError('Could not fetch metrics for train_tune_06a59_00019: both result.json and progress.csv were not found at /Users/sajishunnarah/ray_results/train_tune_2025-12-16_21-20-59/train_tune_06a59_00019_19_batch_size=128,lr=0.0002,momentum=0.9066,optimizer=sgd,weight_decay=0.0000_2025-12-16_21-20-59')\n",
                        "2025-12-16 21:51:50,801\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "No best trial found for the given metric: accuracy. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run Ray Tune hyperparameter search\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# num_samples: number of different configurations to try\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# max_num_epochs: maximum epochs per trial\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m results = \u001b[43mcommon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainset_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Try 20 different configurations\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_num_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Max 6 epochs per trial\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to 1 if you have GPU\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/common.py:263\u001b[39m, in \u001b[36mtune_hyperparameters\u001b[39m\u001b[34m(model_class, trainset, testset, num_samples, max_num_epochs, gpus_per_trial)\u001b[39m\n\u001b[32m    247\u001b[39m scheduler = ASHAScheduler(\n\u001b[32m    248\u001b[39m     max_t=max_num_epochs,\n\u001b[32m    249\u001b[39m     grace_period=\u001b[32m1\u001b[39m,\n\u001b[32m    250\u001b[39m     reduction_factor=\u001b[32m2\u001b[39m\n\u001b[32m    251\u001b[39m )\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Run hyperparameter search\u001b[39;00m\n\u001b[32m    254\u001b[39m tuner = tune.Tuner(\n\u001b[32m    255\u001b[39m     tune.with_resources(\n\u001b[32m    256\u001b[39m         train_tune,\n\u001b[32m    257\u001b[39m         resources={\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m: gpus_per_trial}\n\u001b[32m    258\u001b[39m     ),\n\u001b[32m    259\u001b[39m     tune_config=tune.TuneConfig(\n\u001b[32m    260\u001b[39m         metric=\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    261\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    262\u001b[39m         scheduler=scheduler,\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m         num_samples=num_samples,\n\u001b[32m    264\u001b[39m     ),\n\u001b[32m    265\u001b[39m     param_space=config,\n\u001b[32m    266\u001b[39m )\n\u001b[32m    268\u001b[39m results = tuner.fit()\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Print best results\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/.venv/lib/python3.12/site-packages/ray/tune/result_grid.py:161\u001b[39m, in \u001b[36mResultGrid.get_best_result\u001b[39m\u001b[34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[39m\n\u001b[32m    150\u001b[39m     error_msg = (\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo best trial found for the given metric: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    152\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m._experiment_analysis.default_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis means that no trial has reported this metric\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m     )\n\u001b[32m    155\u001b[39m     error_msg += (\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trial_to_result(best_trial)\n",
                        "\u001b[31mRuntimeError\u001b[39m: No best trial found for the given metric: accuracy. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
                    ]
                }
            ],
            "source": [
                "# Run Ray Tune hyperparameter search\n",
                "# num_samples: number of different configurations to try\n",
                "# max_num_epochs: maximum epochs per trial\n",
                "results = common.tune_hyperparameters(\n",
                "    Net, \n",
                "    trainset_ref, \n",
                "    testset_ref, \n",
                "    num_samples=20,  # Try 20 different configurations\n",
                "    max_num_epochs=6,  # Max 6 epochs per trial\n",
                "    gpus_per_trial=0  # Set to 1 if you have GPU\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyze Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get best trial\n",
                "best_result = results.get_best_result(\"accuracy\", \"max\")\n",
                "\n",
                "print(\"Best Hyperparameters:\")\n",
                "print(f\"  Learning Rate: {best_result.config['lr']:.6f}\")\n",
                "print(f\"  Batch Size: {best_result.config['batch_size']}\")\n",
                "print(f\"  Optimizer: {best_result.config['optimizer']}\")\n",
                "print(f\"  Momentum: {best_result.config['momentum']:.4f}\")\n",
                "print(f\"  Weight Decay: {best_result.config['weight_decay']:.6f}\")\n",
                "print(f\"\\nBest Validation Accuracy: {best_result.metrics['accuracy']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View results as a dataframe\n",
                "import pandas as pd\n",
                "df = results.get_dataframe()\n",
                "\n",
                "# Show top 10 configurations by accuracy\n",
                "df_sorted = df.sort_values('accuracy', ascending=False)\n",
                "print(\"\\nTop 10 Configurations:\")\n",
                "print(df_sorted[['config/lr', 'config/batch_size', 'config/optimizer', \n",
                "                 'config/momentum', 'config/weight_decay', 'accuracy', 'loss']].head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train Final Model with Best Hyperparameters\n",
                "\n",
                "Now use the best hyperparameters to train your final model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create final model with best hyperparameters\n",
                "final_model = Net()\n",
                "\n",
                "best_config = best_result.config\n",
                "\n",
                "common.train(\n",
                "    final_model,\n",
                "    trainset,\n",
                "    testset,\n",
                "    learning_rate=best_config['lr'],\n",
                "    batch_size=int(best_config['batch_size']),\n",
                "    optimizer=best_config['optimizer'],\n",
                "    momentum=best_config['momentum'],\n",
                "    weight_decay=best_config['weight_decay'],\n",
                "    num_epochs=10  # Train longer for final model\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Your Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the trained model\n",
                "torch.save(final_model.state_dict(), 'cifar_net_tuned.pth')\n",
                "print(\"Model saved to cifar_net_tuned.pth\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
